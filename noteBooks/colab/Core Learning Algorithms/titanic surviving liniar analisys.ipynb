{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"titanic surviving liniar analisys.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPkPU8BSjEeN133o9I1NPPw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2DDfqke6s6YA"},"source":["\n","installing with pip\n","\n"]},{"cell_type":"code","metadata":{"id":"RpwqxDvds7k0","executionInfo":{"status":"ok","timestamp":1622050047505,"user_tz":-180,"elapsed":2584,"user":{"displayName":"or yanko","photoUrl":"","userId":"07220515575693711858"}}},"source":["!pip install -q sklearn\n"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Paf7uycKtC2Q"},"source":["imports"]},{"cell_type":"code","metadata":{"id":"NOCqDVMcBQQW","executionInfo":{"status":"ok","timestamp":1622050049264,"user_tz":-180,"elapsed":1766,"user":{"displayName":"or yanko","photoUrl":"","userId":"07220515575693711858"}}},"source":["%tensorflow_version 2.x\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","import tensorflow as tf\n","import tensorflow.compat.v2.feature_column as fc\n","from six.moves import urllib\n","from IPython.display import  clear_output\n","import matplotlib as plt\n","import pandas as pd\n","import numpy as np"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HjG1O_D8tHgD"},"source":["load database"]},{"cell_type":"code","metadata":{"id":"3VZ2YFmVCMWT"},"source":["# Load dataset.\n","dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n","dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n","y_train = dftrain.pop('survived')\n","y_eval = dfeval.pop('survived')\n","\n","CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n","                       'embark_town', 'alone']\n","NUMERIC_COLUMNS = ['age', 'fare']\n","\n","feature_columns = []\n","for feature_name in CATEGORICAL_COLUMNS:\n","  vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n","  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n","\n","for feature_name in NUMERIC_COLUMNS:\n","  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n","\n","print(feature_columns)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ireOHpwkGnVk"},"source":["**train the machine** "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BL3EtTA9Dbjq","executionInfo":{"status":"ok","timestamp":1622050070796,"user_tz":-180,"elapsed":6931,"user":{"displayName":"or yanko","photoUrl":"","userId":"07220515575693711858"}},"outputId":"f4f22697-ea47-4da7-e8fd-5536dcf7f734"},"source":["def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n","  def input_function():  # inner function, this will be returned\n","    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n","    if shuffle:\n","      ds = ds.shuffle(1000)  # randomize order of data\n","    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n","    return ds  # return a batch of the dataset\n","  return input_function  # return a function object for use\n","\n","train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n","eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n","\n","# We create a linear estimtor by passing the feature columns we created earlier\n","linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n","\n","linear_est.train(train_input_fn)  # train\n","result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by testing on tetsing data\n","\n","clear_output()  # clears console output\n","print('accuracy:', result['accuracy'])  # the result variable is simply a dict of stats about our model\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["accuracy: 0.7462121\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i-pTJk6PK-Zp"},"source":["get prediction"]},{"cell_type":"code","metadata":{"id":"e1sbt2mQGlOJ"},"source":["result = list(linear_est.predict(eval_input_fn))\n","clear_output()  # clears console output\n","i = 0\n","for i in range(0, len(y_eval-1)):\n","  print(dfeval.loc[i])\n","  print('is survived:', y_eval[i])\n","  print('survival chances:', result[i]['probabilities'][1]*100 ,'%')\n","  print()"],"execution_count":null,"outputs":[]}]}